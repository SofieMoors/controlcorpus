{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e36e76a-6eef-462c-99e7-07cc648f8bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b089d-ec00-4c72-b3cb-c6d07b0aeb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install grapheme\n",
    "!pip install pandas\n",
    "!pip install seaborn\n",
    "!pip install scipy\n",
    "!pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "990268fc-3457-4dcf-b1cd-d6e16345d4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "import os \n",
    "from itertools import combinations \n",
    "import grapheme \n",
    "from collatex import * \n",
    "from tqdm import tqdm \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sb \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from lxml import etree\n",
    "from re import sub \n",
    "import xml.etree.ElementTree as ET\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49c9c8ee-642a-4691-a87d-b66097785d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigles = [os.path.basename(fn).replace('xml_', '').replace('.xml', '') for fn in glob('../data/xml/*.xml')] \n",
    "sigles = sorted(sigles)\n",
    "sigles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7af21749-fa18-4117-a18d-56b7546856b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gap_lines(tree):\n",
    "    gap_lines = []\n",
    "    for text in tree.iterfind('.//' + \"{\" + NSMAP[\"MVN\"] + \"}\" + 'text'):\n",
    "        if 'n' in text.attrib:\n",
    "            for line in text.iterfind('.//' + \"{\" + NSMAP[\"MVN\"] + \"}\" + 'l'):\n",
    "                if line.find('.//' + \"{\" + NSMAP[\"MVN\"] + \"}\" + 'gap') is not None:\n",
    "                    if 'n' in line.attrib:\n",
    "                        n_value = line.attrib['n']\n",
    "                        parts = n_value.split('_')\n",
    "                        if len(parts) > 1:\n",
    "                            k = \"_\".join(parts[1:])  # Join the parts after the first underscore\n",
    "                        else:\n",
    "                            k = n_value\n",
    "                        gap_lines.append(k)\n",
    "\n",
    "    return gap_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "174436a8-008f-4428-ab15-d2609a00dd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "NSMAP = {'MVN': 'http://www.tei-c.org/ns/1.0'} \n",
    "removes = ('teiHeader', 'fw', 'supplied', 'abbr')\n",
    "removes_expan_false = ('teiHeader', 'fw', 'supplied', 'ex', 'expan')\n",
    "chars = {'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l','m', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'}       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2a2e7ee-87fe-4cc7-b328-551ba3caaa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1107\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def extract_lines(xml_file, expan = True,  \n",
    "                  punct = True, lower = True,\n",
    "                  sep_abbr = True): \n",
    "    lines = {}\n",
    "    tree = etree.parse(xml_file) \n",
    "    \n",
    "    if expan:\n",
    "        etree.strip_elements(tree, (\"{\"+ NSMAP[\"MVN\"]+ \"}\" + s for s in removes), with_tail=False) \n",
    "    else: \n",
    "        etree.strip_elements(tree, (\"{\"+ NSMAP[\"MVN\"]+ \"}\" + s for s in removes_expan_false), with_tail=False)\n",
    "  \n",
    "    context = etree.iterwalk(tree, events=(\"start\", \"end\"))\n",
    "    text = u\"\" \n",
    "    k = '' \n",
    "    \n",
    "    for action, node in context: \n",
    "        tag_only = node.tag.replace(\"{http://www.tei-c.org/ns/1.0}\",\"\")  #remove ns for easier access\n",
    "        if 'n' in node.attrib and tag_only == 'text': \n",
    "            title = node.attrib['n'] \n",
    "\n",
    "        if 'n' in node.attrib and tag_only == \"l\":\n",
    "           # k = node.attrib['n']\n",
    "            n_value = node.attrib['n']\n",
    "            parts = n_value.split('_')\n",
    "            if len(parts) > 1:\n",
    "                k = \"_\".join(parts[1:])  \n",
    "            else:\n",
    "                k = n_value \n",
    "        # if a new pb (standalone element) is processed:\n",
    "        if action == 'start' and tag_only == 'text': \n",
    "            continue\n",
    "            \n",
    "        elif action == 'start' and tag_only == 'lg':\n",
    "            continue \n",
    "            \n",
    "        # if new lb (standalone) is processed:\n",
    "        elif action == 'start' and tag_only == 'lb':\n",
    "            continue\n",
    "\n",
    "        # list elements which you want to iterate through. this is not really neccessary.\n",
    "        elif tag_only in (\"group\",\"text\",\"MVN\",\"body\",\"cb\",\"p\",\"note\"):\n",
    "            continue\n",
    "\n",
    "        # for all other elements, distinguish bet ween the start-event of the processing and\n",
    "        # and the end-event. Attach the tail AFTER the child nodes were processed (= end-event) \n",
    "         \n",
    "        elif action == 'start':\n",
    "            #comment the following two lines out to not get the element markers\n",
    "            #f.write(f\"[{tag_only}]\") \n",
    "            #text += f\"[{tag_only}]\"\n",
    "\n",
    "            ############################################################################\n",
    "            ########## filter out special characters, bars,                   ##########\n",
    "            ########## superscript, or specific tags.                         ##########\n",
    "            ############################################################################\n",
    "                    \n",
    "            \n",
    "            #if a special glyph is present, encode it accordingly\n",
    "                \n",
    "            if tag_only == 'g':\n",
    "                if sep_abbr:\n",
    "                    if node.attrib['ref'] == '#bar': # ā, ē, ī, ō, ū, n̄ etc.\n",
    "                        text += u'\\u005f' #low line _\n",
    "\n",
    "                    elif node.attrib['ref'] == '#apomod': # ʼ\n",
    "                        text += u'\\u02bc'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#usmod': # ꝰ\n",
    "                        text += u'\\ua770' \n",
    "\n",
    "                    elif node.attrib['ref'] == '#condes': # ꝯ\n",
    "                        text += u'\\ua76f'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#para': # ¶\n",
    "                        text += u'\\xb6'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#etfin': # ꝫ\n",
    "                        text += u'\\ua76b'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#pbardes': # ꝑ\n",
    "                        text += '\\ua751'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#pbardes': # ꝕ\n",
    "                        text += u'\\ua755'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#pflour': # ꝓ\n",
    "                        text += u'\\ua753'\n",
    "                        \n",
    "                    elif node.attrib['ref'] == '#rrot': #ꝛ\n",
    "                        text += (u'\\uA75B')\n",
    "                    else:\n",
    "                        text += str(node.attrib['ref']) # get the actual ref if there still are any left\n",
    "                    \n",
    "                else:\n",
    "                    if node.attrib['ref'] == '#bar': # ā, ē, ī, ō, ū, n̄ etc.\n",
    "                        text += u'\\u0304'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#apomod': # ʼ\n",
    "                        text += u'\\u02bc'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#usmod': # ꝰ\n",
    "                        text += u'\\ua770'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#condes': # ꝯ\n",
    "                        text += u'\\ua76f'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#para': # ¶\n",
    "                        text += u'\\xb6'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#etfin': # ꝫ\n",
    "                        text += u'\\ua76b'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#pbardes': # ꝑ\n",
    "                        text += u'\\ua751'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#pbardes': # ꝕ\n",
    "                        text += u'\\ua755'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#pflour': # ꝓ\n",
    "                        text += u'\\ua753'\n",
    "                        \n",
    "                    elif node.attrib['ref'] == '#rrot': #ꝛ\n",
    "                        text += (u'\\uA75B')\n",
    "\n",
    "                    else:\n",
    "                        node.attrib['ref']\n",
    "                        text += str(node.attrib['ref']) # get the actual ref if there still are any left\n",
    "\n",
    "            # encode superscript letters\n",
    "            superscript_dict = {'a':'ᵃ', 'b':'ᵇ', 'c':'ᶜ', 'd':'ᵈ', 'e':'ᵉ', 'f':'ᶠ',\n",
    "                               'g':'ᵍ', 'h':'ʰ', 'i':'ᶦ', 'j':'ʲ', 'k':'ᵏ', 'l':'ˡ', \n",
    "                                'm':'ᵐ', 'n':'ⁿ', 'o':'ᵒ', 'p':'ᵖ', 'r':'ʳ', 's':'ˢ', \n",
    "                                't':'ᵗ', 'u':'ᵘ', 'v':'ᵛ', 'w':'ʷ', 'x':'ˣ', 'y': 'ʸ', 'z': 'ᶻ'}\n",
    "\n",
    "            if tag_only == 'hi' and 'rend' in node.attrib and node.attrib['rend'] == 'superscript': #rend(ition) supplies information about the appearance of an element\n",
    "                if node.text in superscript_dict:\n",
    "                    text += str(superscript_dict[node.text]).strip()\n",
    "\n",
    "            elif tag_only == 'ex':\n",
    "                    text += str('*'+node.text+'€')\n",
    "            \n",
    "            elif tag_only == 'del':\n",
    "            # Just keep the text as is without any modifications\n",
    "                if node.text:\n",
    "                    text += f\"<del>{node.text}</del>\" \n",
    "\n",
    "            # encode punctuation marks\n",
    "            elif tag_only == 'pc':\n",
    "                text += str(node.text).strip()\n",
    "\n",
    "            # encode roman numerals\n",
    "            elif tag_only == 'num':\n",
    "                if node.text:\n",
    "                    text += str('.'+node.text+'.').strip()\n",
    "            \n",
    "            elif tag_only == 'damage':\n",
    "                text += ('[...]')\n",
    "                \n",
    "            elif tag_only == 'del':\n",
    "                def strikethrough(text):\n",
    "                    return ''.join([char + '\\u0336' for char in node.text])\n",
    "                if node.text: \n",
    "                    text += strikethrough(node.text)\n",
    "\n",
    "            # if there is still a node with text in it\n",
    "            elif (node.text):\n",
    "                text += node.text        \n",
    "\n",
    "        # after the child elements\n",
    "        elif action == 'end':\n",
    "            #if there is a tail\n",
    "            if (node.tail and node.tail not in \"\\t\"): #if the tail is not yet in the text \n",
    "                #comment the following two lines out to not get the tail marker\n",
    "                #text += \"[tail]\"\n",
    "                #f.write(\"[tail]\")\n",
    "                #append to text-concatenation\n",
    "                text += str(node.tail)\n",
    "\n",
    "        if tag_only == 'l' or tag_only == 'lg':\n",
    "            if k: \n",
    "                text = sub(r'\\n', '', text) \n",
    "                \n",
    "        if tag_only == 'lb':\n",
    "            if k:\n",
    "                text = sub(r'\\n', '', text)\n",
    "                if not punct:\n",
    "                    punctuation_with_pilcrow = string.punctuation + '¶' + '⸫'\n",
    "                    text = text.translate(str.maketrans('', '', punctuation_with_pilcrow))\n",
    "                    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "                if lower: \n",
    "                    text = text.lower()\n",
    "                   \n",
    "                    #text = text[::-1]\n",
    "                  \n",
    "                lines[k] = text \n",
    "\n",
    "                text = ''   \n",
    "    # catch dangling last line (if applicable):\n",
    "    if text:\n",
    "        lines[k] = text\n",
    "    text = sub(r'\\n', '', text)  \n",
    "\n",
    "    if not punct:\n",
    "        punctuation_with_pilcrow = string.punctuation + '¶' + '⸫'\n",
    "        text = text.translate(str.maketrans('', '', punctuation_with_pilcrow))\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        #text = text.translate(str.maketrans('', '', string.punctuation))  # Verwijder interpunctie\n",
    "    if lower:\n",
    "        text = text.lower() \n",
    "    lines[k] = text \n",
    "    num_orig_lines = len(lines)\n",
    "    print(num_orig_lines)\n",
    "    # remove lines with gaps:\n",
    "    #gap_lines = get_gap_lines(tree)\n",
    "    #lines = {k:v for k, v in lines.items() if k not in gap_lines}\n",
    "    #print(f'-> removed {num_orig_lines - len(lines)} lines with gaps')\n",
    "    #lines = {k:v for k, v in lines.items() if v.strip()} #if a line with a gap is removed, remove empty key, strip() removes spaces #The items() method returns a key-value pair\n",
    "    \n",
    "    return lines\n",
    "    #num_orig_lines = len(lines)\n",
    "    #print(num_orig_lines)\n",
    "d = extract_lines(f'../data/xml/xml_{sigles[1]}.xml', expan = True, punct = True, lower = True)\n",
    "#print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15f0fa15-7e55-4f6d-8f6e-7e11a8ca9d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|████████████████████████▌                     | 8/15 [00:00<00:00, 39.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115\n",
      "1107\n",
      "1111\n",
      "1106\n",
      "1108\n",
      "1132\n",
      "1112\n",
      "897\n",
      "709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 15/15 [00:00<00:00, 37.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1106\n",
      "1116\n",
      "1111\n",
      "1107\n",
      "1114\n",
      "401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mss = {} \n",
    "for sigle in tqdm(sigles): \n",
    "    mss[sigle] = extract_lines(f'../data/xml/xml_{sigle}.xml',\n",
    "                               expan = True, punct = True, lower = True,\n",
    "                               sep_abbr = False) \n",
    "#print(mss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e1aeaa1-891a-4a05-a0f3-9829b357478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "idx = set()\n",
    "for ms in mss:\n",
    "    idx.update(set(mss[ms].keys()))\n",
    "idx = sorted(idx)\n",
    "witnesses = sorted(mss.keys())\n",
    "\n",
    "lines = np.empty([len(idx), len(witnesses)], dtype=\"object\")\n",
    "\n",
    "for ms in mss.keys():\n",
    "    for l in mss[ms]:\n",
    "        lines[idx.index(l), witnesses.index(ms)] = mss[ms][l].replace('*', '<i>').replace('€', '</i>')\n",
    "\n",
    "lines = pd.DataFrame(lines, index=idx, columns=witnesses)\n",
    "lines.to_html('../data/xlsx/synoptic.html', escape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f4921b-1a1b-4d73-9702-7eb6863de045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66339e93-17e9-4b57-a64b-d30cc5586283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
